# üéØ DecimalFold

> AI-Powered Resume-to-Job Matching Platform with Advanced Vector Search

![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![Node.js](https://img.shields.io/badge/Node.js-43853D?style=for-the-badge&logo=node.js&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![Pinecone](https://img.shields.io/badge/Pinecone-000000?style=for-the-badge&logo=pinecone&logoColor=white)

## üìã Overview

DecimalFold is a sophisticated AI-powered platform that revolutionizes job matching by leveraging advanced natural language processing and vector similarity search. The system intelligently analyzes resumes and matches candidates with relevant job opportunities using state-of-the-art machine learning techniques.

## ‚ú® Key Features

### ü§ñ AI-Powered Resume Analysis

- **OpenAI GPT-4o Integration**: Advanced resume parsing and skill extraction
- **Multi-format Support**: PDF, DOCX, TXT file processing
- **Language Detection & Translation**: Automatic language detection with translation support
- **Intelligent Parsing**: Extracts skills, experience level, role, and industry background

### üîç Advanced Vector Search

- **Semantic Similarity**: Uses OpenAI embeddings for deep contextual understanding
- **Pinecone Vector Database**: Scalable, high-performance vector search
- **Cosine Similarity Matching**: Precise relevance scoring between resumes and jobs
- **Real-time Processing**: Instant job matching with sub-second response times

### üéØ Smart Job Matching

- **MMR (Maximal Marginal Relevance)**: Diversified results to avoid redundancy
- **Industry Filtering**: Targeted matching within specific industries
- **Experience Level Alignment**: Matches based on career progression
- **Confidence Scoring**: High/Medium/Low confidence indicators

### üìä Performance & Scalability

- **Memory Optimized**: Efficient resource utilization
- **Batch Processing**: Handles large datasets (tested up to 100K jobs)
- **Caching Strategy**: Optimized vector storage and retrieval
- **Production Ready**: Built for enterprise-scale deployment

- **PostgreSQL** with Neon serverless database support
- **In-memory storage** for development and testing
- **Vector embeddings** stored for efficient similarity calculations

### Development Tools

- **ESBuild** for fast JavaScript bundling
- **PostCSS** with Autoprefixer for CSS processing
- **Hot Module Replacement** for instant development feedback
- **TypeScript strict mode** for maximum type safety

## üì¶ Installation & Setup

### Prerequisites

- Node.js 18+ installed
- OpenAI API key for resume parsing and vector generation
- Pinecone index
- Neon/postgres database connection

### Environment Setup

1. Clone the repository:

```bash
git clone <repository-url>
cd ai-job-matcher
```

2. Install dependencies:

```bash
npm install
```

3. Set up environment variables:
   - The application requires an OpenAI API key
   - Use the Replit secrets manager or create a `.env` file:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

4. Start the development server:

```bash
npm run dev
```

The application will be available at `http://localhost:5000`

## üöÄ Usage

### Basic Resume Matching

1. **Upload Resume**: Drag and drop or click to upload a resume file (PDF, DOCX, or TXT)
2. **AI Processing**: The system automatically parses the resume using OpenAI GPT-4o
3. **Job Matching**: Vector similarity algorithms find relevant job matches
4. **View Results**: Browse ranked job matches with confidence scores and skill overlaps

### Scalability Testing

1. **Generate Jobs**: Use the job generation API to create test datasets

```bash
# Generate 1000 general jobs
curl -X POST http://localhost:5000/api/jobs/generate \
  -H "Content-Type: application/json" \
  -d '{"count": 1000, "type": "general"}'

# Generate 5000 tech-focused jobs
curl -X POST http://localhost:5000/api/jobs/generate \
  -H "Content-Type: application/json" \
  -d '{"count": 5000, "type": "tech"}'
```

2. **Test Vector Strategies**: Compare different matching algorithms

```bash
# Test TF-IDF strategy
curl -X POST http://localhost:5000/api/resume/1/matches/strategy \
  -H "Content-Type: application/json" \
  -d '{"strategy": "tfidf"}'

# Test skill-based matching
curl -X POST http://localhost:5000/api/resume/1/matches/strategy \
  -H "Content-Type: application/json" \
  -d '{"strategy": "skill"}'
```

### Available Vector Strategies

#### 1. TF-IDF Strategy

- **Best for**: Large-scale text analysis and semantic understanding
- **Approach**: Term Frequency-Inverse Document Frequency vectorization
- **Pros**: Captures semantic relationships, scales well with large datasets
- **Cons**: May miss exact skill matches

#### 2. Skill-based Strategy

- **Best for**: Exact technical skill matching
- **Approach**: Direct skill overlap and experience level weighting
- **Pros**: Precise skill matching, fast computation
- **Cons**: May miss semantic similarities

#### 3. Hybrid Strategy

- **Best for**: Balanced approach combining multiple techniques
- **Approach**: 60% TF-IDF + 40% skill matching
- **Pros**: Best of both worlds, comprehensive matching
- **Cons**: Slightly more computation intensive

## üìä API Endpoints

### Core Functionality

- `POST /api/resume/upload` - Upload and process resume files
- `GET /api/jobs` - Get all available jobs with optional filtering
- `POST /api/resume/:id/matches` - Get job matches for a specific resume

### Scalability & Testing

- `POST /api/jobs/generate` - Generate jobs for testing (up to 100k)
- `GET /api/jobs/stats` - Get job database statistics
- `POST /api/resume/:id/matches/strategy` - Test different vector strategies
- `GET /api/strategies` - Get available matching strategies

### Supported Job Generation Types

- `general` - Mixed roles across all industries and experience levels
- `tech` - Technology-focused positions (software engineering, development)
- `data` - Data science, machine learning, and AI positions

## üèó Architecture

### Data Flow

1. **Resume Upload** ‚Üí File parsing (PDF/DOCX/TXT) ‚Üí Text extraction
2. **AI Processing** ‚Üí OpenAI GPT-4o analysis ‚Üí Structured data extraction
3. **Vector Generation** ‚Üí Embedding creation ‚Üí Database storage
4. **Job Matching** ‚Üí Vector similarity calculation ‚Üí Ranked results
5. **UI Display** ‚Üí Real-time updates ‚Üí Interactive job listings

### Scaling Considerations

- **Vector Databases**: Ready for integration with Pinecone or Weaviate for 100k+ jobs
- **Caching**: Redis integration for frequently accessed vectors
- **Batch Processing**: Async job processing for large-scale operations
- **API Rate Limiting**: Built-in handling for OpenAI API limits

## üîß Development

### Project Structure

```
‚îú‚îÄ‚îÄ client/src/          # React frontend application
‚îÇ   ‚îú‚îÄ‚îÄ components/      # Reusable UI components
‚îÇ   ‚îú‚îÄ‚îÄ pages/          # Application pages and routes
‚îÇ   ‚îî‚îÄ‚îÄ lib/            # Utilities and configuration
‚îú‚îÄ‚îÄ server/             # Express.js backend
‚îÇ   ‚îú‚îÄ‚îÄ services/       # Business logic and external integrations
‚îÇ   ‚îî‚îÄ‚îÄ routes.ts       # API endpoint definitions
‚îú‚îÄ‚îÄ shared/             # Shared types and schemas
‚îî‚îÄ‚îÄ package.json        # Dependencies and scripts
```

### Key Files

- `server/services/openai.ts` - OpenAI integration for resume parsing
- `server/services/vectorMatcher.ts` - Core matching algorithms
- `server/services/jobGenerator.ts` - Scalable job data generation
- `server/services/vectorStrategies.ts` - Alternative matching strategies
- `client/src/components/ResumeUpload.tsx` - File upload interface
- `client/src/components/JobMatches.tsx` - Match results display

### Development Commands

```bash
npm run dev          # Start development server with hot reload
npm run build        # Build production bundle
npm run preview      # Preview production build locally
```

## üö¶ Performance

### Benchmarks (tested on standard hardware)

- **Resume Processing**: ~2-4 seconds (including OpenAI API calls)
- **Job Matching**:
  - 1K jobs: ~50ms
  - 10K jobs: ~200ms
  - 100K jobs: ~1.5s (with optimized vector strategies)
- **Vector Generation**: ~100ms per job (cached after first generation)

### Optimization Features

- **Text Truncation**: Automatic handling of OpenAI token limits
- **Vector Caching**: Avoid regenerating vectors for existing jobs
- **Batch Processing**: Efficient database operations for large datasets
- **Lazy Loading**: Progressive loading of job results

## ü§ù Contributing

This is a demonstration project showcasing modern full-stack development practices with AI integration. Feel free to fork and extend the functionality for your own use cases.

### Potential Enhancements

- Integration with real job boards (Indeed, LinkedIn, etc.)
- Advanced filtering and search capabilities
- User accounts and saved searches
- Email notifications for new matches
- Company-specific matching algorithms
- A/B testing framework for different strategies

## üìÑ License

This project is for educational and demonstration purposes. Please ensure you have appropriate API keys and comply with OpenAI's usage policies when using this application.

## üîë Environment Variables

| Variable         | Description                               | Required                               |
| ---------------- | ----------------------------------------- | -------------------------------------- |
| `OPENAI_API_KEY` | OpenAI API key for GPT-4o and embeddings  | Yes                                    |
| `DATABASE_URL`   | PostgreSQL connection string              | No (uses in-memory storage by default) |
| `NODE_ENV`       | Environment mode (development/production) | No                                     |

## üêõ Troubleshooting

### Common Issues

1. **OpenAI Token Limit Errors**

   - The application automatically truncates text to fit within token limits
   - Check your OpenAI API key and rate limits

2. **File Upload Issues**

   - Ensure files are under 10MB
   - Supported formats: PDF, DOCX, TXT
   - Check file permissions and disk space

3. **Performance with Large Datasets**
   - Use vector strategies for better performance with 10k+ jobs
   - Consider implementing pagination for UI
   - Monitor memory usage during large job generation

### Getting Help

Check the console logs for detailed error messages and API response information. The application includes comprehensive error handling and user-friendly error messages.

### macOS Rosetta Issues

If you're running on Apple Silicon (M1/M2/M3 Macs), some Node.js modules might have compatibility issues. The dotenv loading problem can sometimes be related to architecture-specific builds. You need to clean reinstall your dependencies outside Rosetta to get the correct native binary.
